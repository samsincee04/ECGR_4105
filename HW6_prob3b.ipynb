{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZRsFuPFNO67I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## CIFAR-10 normalization vals(3 channels, RGB)\n",
        "mean = (0.4914, 0.4822, 0.4465) ## one mean + one std per channel\n",
        "std =  (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), ## convert PIL img to tensor, convert pixel vals to 0-1 float\n",
        "    transforms.Normalize(mean, std)\n",
        "\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform) ## load training split of CIFAR-10\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform) ## load the test set of 10k images\n",
        "\n",
        "## load data in mini-batches\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "euTEo8KzPo0c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(3072, 512), # Hidden layer 1\n",
        "    nn.ReLU(),\n",
        "\n",
        "    nn.Linear(512, 256), # Hidden layer 2\n",
        "    nn.ReLU(),\n",
        "\n",
        "    nn.Linear(256, 128), # Hidden Layer 3\n",
        "    nn.ReLU(),\n",
        "\n",
        "    nn.Linear(128, 10) # Output layer(10 classes)\n",
        ")\n",
        "print(model)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_sH4xeFQFT3",
        "outputId": "96d683b2-d9df-475b-ac44-390756a662c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Flatten(start_dim=1, end_dim=-1)\n",
            "  (1): Linear(in_features=3072, out_features=512, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (4): ReLU()\n",
            "  (5): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (6): ReLU()\n",
            "  (7): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss, Optimizer, Training setup\n",
        "loss_fn = nn.CrossEntropyLoss() ## combination of softmax and Nllloss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 300\n",
        "\n",
        "\n",
        "# Training Loop\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "epoch_times = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Compute accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    # Metrics for the epoch\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    accuracy = correct / total\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    train_losses.append(avg_loss)\n",
        "    train_accuracies.append(accuracy)\n",
        "    epoch_times.append(elapsed)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}  \"\n",
        "          f\"Loss: {avg_loss:.4f}  \"\n",
        "          f\"Accuracy: {accuracy:.4f}  \"\n",
        "          f\"Time: {elapsed:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xE9xYuDKQIx9",
        "outputId": "73593c10-54c8-4542-dc9e-98b1a2007da8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300  Loss: 1.6610  Accuracy: 0.4112  Time: 12.89s\n",
            "Epoch 2/300  Loss: 1.4504  Accuracy: 0.4874  Time: 12.50s\n",
            "Epoch 3/300  Loss: 1.3408  Accuracy: 0.5263  Time: 12.59s\n",
            "Epoch 4/300  Loss: 1.2628  Accuracy: 0.5523  Time: 12.38s\n",
            "Epoch 5/300  Loss: 1.1847  Accuracy: 0.5781  Time: 12.36s\n",
            "Epoch 6/300  Loss: 1.1092  Accuracy: 0.6072  Time: 12.44s\n",
            "Epoch 7/300  Loss: 1.0444  Accuracy: 0.6269  Time: 12.23s\n",
            "Epoch 8/300  Loss: 0.9816  Accuracy: 0.6488  Time: 12.48s\n",
            "Epoch 9/300  Loss: 0.9215  Accuracy: 0.6715  Time: 12.38s\n",
            "Epoch 10/300  Loss: 0.8681  Accuracy: 0.6894  Time: 12.34s\n",
            "Epoch 11/300  Loss: 0.8207  Accuracy: 0.7070  Time: 12.46s\n",
            "Epoch 12/300  Loss: 0.7619  Accuracy: 0.7256  Time: 12.38s\n",
            "Epoch 13/300  Loss: 0.7152  Accuracy: 0.7405  Time: 12.30s\n",
            "Epoch 14/300  Loss: 0.6733  Accuracy: 0.7590  Time: 12.42s\n",
            "Epoch 15/300  Loss: 0.6427  Accuracy: 0.7719  Time: 12.53s\n",
            "Epoch 16/300  Loss: 0.6029  Accuracy: 0.7831  Time: 12.61s\n",
            "Epoch 17/300  Loss: 0.5677  Accuracy: 0.7965  Time: 12.66s\n",
            "Epoch 18/300  Loss: 0.5485  Accuracy: 0.8029  Time: 12.44s\n",
            "Epoch 19/300  Loss: 0.5246  Accuracy: 0.8121  Time: 12.45s\n",
            "Epoch 20/300  Loss: 0.5034  Accuracy: 0.8198  Time: 12.33s\n",
            "Epoch 21/300  Loss: 0.4677  Accuracy: 0.8331  Time: 12.34s\n",
            "Epoch 22/300  Loss: 0.4615  Accuracy: 0.8342  Time: 12.37s\n",
            "Epoch 23/300  Loss: 0.4324  Accuracy: 0.8454  Time: 12.40s\n",
            "Epoch 24/300  Loss: 0.4224  Accuracy: 0.8485  Time: 12.52s\n",
            "Epoch 25/300  Loss: 0.4116  Accuracy: 0.8520  Time: 12.57s\n",
            "Epoch 26/300  Loss: 0.3932  Accuracy: 0.8618  Time: 12.67s\n",
            "Epoch 27/300  Loss: 0.3890  Accuracy: 0.8635  Time: 12.71s\n",
            "Epoch 28/300  Loss: 0.3653  Accuracy: 0.8711  Time: 12.70s\n",
            "Epoch 29/300  Loss: 0.3561  Accuracy: 0.8745  Time: 12.42s\n",
            "Epoch 30/300  Loss: 0.3590  Accuracy: 0.8755  Time: 12.39s\n",
            "Epoch 31/300  Loss: 0.3375  Accuracy: 0.8816  Time: 12.46s\n",
            "Epoch 32/300  Loss: 0.3258  Accuracy: 0.8856  Time: 12.41s\n",
            "Epoch 33/300  Loss: 0.3358  Accuracy: 0.8835  Time: 12.12s\n",
            "Epoch 34/300  Loss: 0.3061  Accuracy: 0.8936  Time: 12.21s\n",
            "Epoch 35/300  Loss: 0.3123  Accuracy: 0.8930  Time: 12.55s\n",
            "Epoch 36/300  Loss: 0.2933  Accuracy: 0.8993  Time: 12.49s\n",
            "Epoch 37/300  Loss: 0.3125  Accuracy: 0.8921  Time: 12.53s\n",
            "Epoch 38/300  Loss: 0.2841  Accuracy: 0.9017  Time: 12.48s\n",
            "Epoch 39/300  Loss: 0.2756  Accuracy: 0.9059  Time: 12.51s\n",
            "Epoch 40/300  Loss: 0.2780  Accuracy: 0.9030  Time: 12.14s\n",
            "Epoch 41/300  Loss: 0.2809  Accuracy: 0.9031  Time: 12.29s\n",
            "Epoch 42/300  Loss: 0.2686  Accuracy: 0.9091  Time: 12.32s\n",
            "Epoch 43/300  Loss: 0.2573  Accuracy: 0.9115  Time: 12.55s\n",
            "Epoch 44/300  Loss: 0.2642  Accuracy: 0.9102  Time: 12.46s\n",
            "Epoch 45/300  Loss: 0.2514  Accuracy: 0.9146  Time: 12.48s\n",
            "Epoch 46/300  Loss: 0.2462  Accuracy: 0.9168  Time: 12.71s\n",
            "Epoch 47/300  Loss: 0.2536  Accuracy: 0.9161  Time: 12.55s\n",
            "Epoch 48/300  Loss: 0.2465  Accuracy: 0.9168  Time: 12.36s\n",
            "Epoch 49/300  Loss: 0.2456  Accuracy: 0.9195  Time: 12.32s\n",
            "Epoch 50/300  Loss: 0.2285  Accuracy: 0.9244  Time: 12.45s\n",
            "Epoch 51/300  Loss: 0.2265  Accuracy: 0.9248  Time: 12.60s\n",
            "Epoch 52/300  Loss: 0.2249  Accuracy: 0.9246  Time: 12.44s\n",
            "Epoch 53/300  Loss: 0.2356  Accuracy: 0.9218  Time: 12.65s\n",
            "Epoch 54/300  Loss: 0.2190  Accuracy: 0.9263  Time: 12.85s\n",
            "Epoch 55/300  Loss: 0.2208  Accuracy: 0.9269  Time: 12.97s\n",
            "Epoch 56/300  Loss: 0.2174  Accuracy: 0.9277  Time: 12.71s\n",
            "Epoch 57/300  Loss: 0.2295  Accuracy: 0.9242  Time: 12.57s\n",
            "Epoch 58/300  Loss: 0.2114  Accuracy: 0.9298  Time: 12.42s\n",
            "Epoch 59/300  Loss: 0.2087  Accuracy: 0.9313  Time: 12.45s\n",
            "Epoch 60/300  Loss: 0.2064  Accuracy: 0.9322  Time: 12.52s\n",
            "Epoch 61/300  Loss: 0.2045  Accuracy: 0.9332  Time: 12.52s\n",
            "Epoch 62/300  Loss: 0.2197  Accuracy: 0.9294  Time: 12.28s\n",
            "Epoch 63/300  Loss: 0.2085  Accuracy: 0.9325  Time: 12.14s\n",
            "Epoch 64/300  Loss: 0.1851  Accuracy: 0.9401  Time: 12.14s\n",
            "Epoch 65/300  Loss: 0.2012  Accuracy: 0.9356  Time: 12.12s\n",
            "Epoch 66/300  Loss: 0.2097  Accuracy: 0.9329  Time: 12.71s\n",
            "Epoch 67/300  Loss: 0.1890  Accuracy: 0.9392  Time: 12.54s\n",
            "Epoch 68/300  Loss: 0.2085  Accuracy: 0.9337  Time: 12.69s\n",
            "Epoch 69/300  Loss: 0.1792  Accuracy: 0.9430  Time: 12.46s\n",
            "Epoch 70/300  Loss: 0.1916  Accuracy: 0.9378  Time: 12.48s\n",
            "Epoch 71/300  Loss: 0.1891  Accuracy: 0.9387  Time: 12.57s\n",
            "Epoch 72/300  Loss: 0.1871  Accuracy: 0.9398  Time: 12.62s\n",
            "Epoch 73/300  Loss: 0.1824  Accuracy: 0.9412  Time: 12.71s\n",
            "Epoch 74/300  Loss: 0.1912  Accuracy: 0.9393  Time: 12.46s\n",
            "Epoch 75/300  Loss: 0.1857  Accuracy: 0.9426  Time: 12.58s\n",
            "Epoch 76/300  Loss: 0.1759  Accuracy: 0.9448  Time: 12.52s\n",
            "Epoch 77/300  Loss: 0.1927  Accuracy: 0.9406  Time: 12.52s\n",
            "Epoch 78/300  Loss: 0.1872  Accuracy: 0.9414  Time: 12.54s\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3494351664.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tobytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3329\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3330\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tostring\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3331\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}