{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABFpyBKGs_sa",
        "outputId": "6025f384-3d51-4444-c934-f03dad794770"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## CIFAR-10 normalization vals(3 channels, RGB)\n",
        "mean = (0.4914, 0.4822, 0.4465) ## one mean + one std per channel\n",
        "std =  (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), ## convert PIL img to tensor, convert pixel vals to 0-1 float\n",
        "    transforms.Normalize(mean, std)\n",
        "\n",
        "])\n",
        "\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform) ## load training split of CIFAR-10\n",
        "test_dataset = CIFAR10(root='./data', train=False, download=True, transform=transform) ## load the test set of 10k images\n",
        "\n",
        "## load data in mini-batches\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "d94FScUIwcTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "560db3a3-9ede-4b21-a4a2-8ce50affd81b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 41.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(3072, 512), # 3072 input features, 512 hidden neurons\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 10) # 512 hidden features, 10 output classes\n",
        ")\n",
        "print(model)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVtV4Pq640wK",
        "outputId": "084606d2-8c64-4e26-8707-3672f4862840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Flatten(start_dim=1, end_dim=-1)\n",
            "  (1): Linear(in_features=3072, out_features=512, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss, Optimizer, Training setup\n",
        "loss_fn = nn.CrossEntropyLoss() ## combination of softmax and Nllloss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "num_epochs = 10\n",
        "\n",
        "\n",
        "# Training Loop\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "epoch_times = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Compute accuracy\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    # Metrics for the epoch\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    accuracy = correct / total\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    train_losses.append(avg_loss)\n",
        "    train_accuracies.append(accuracy)\n",
        "    epoch_times.append(elapsed)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}  \"\n",
        "          f\"Loss: {avg_loss:.4f}  \"\n",
        "          f\"Accuracy: {accuracy:.4f}  \"\n",
        "          f\"Time: {elapsed:.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UujNyJ1b56c2",
        "outputId": "d1b2ef6a-91bb-4fca-92d1-5e838b038402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10  Loss: 896.0957  Accuracy: 0.2299  Time: 13.18s\n",
            "Epoch 2/10  Loss: 902.4521  Accuracy: 0.2421  Time: 12.41s\n",
            "Epoch 3/10  Loss: 882.8511  Accuracy: 0.2487  Time: 12.13s\n",
            "Epoch 4/10  Loss: 899.0643  Accuracy: 0.2530  Time: 11.74s\n",
            "Epoch 5/10  Loss: 797.2623  Accuracy: 0.2490  Time: 11.99s\n",
            "Epoch 6/10  Loss: 868.5199  Accuracy: 0.2557  Time: 11.82s\n",
            "Epoch 7/10  Loss: 808.7268  Accuracy: 0.2558  Time: 11.93s\n",
            "Epoch 8/10  Loss: 759.5083  Accuracy: 0.2592  Time: 11.99s\n",
            "Epoch 9/10  Loss: 675.6210  Accuracy: 0.2613  Time: 11.78s\n",
            "Epoch 10/10  Loss: 714.0831  Accuracy: 0.2551  Time: 11.83s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Load raw CIFAR-10 (no normalization)\n",
        "transform = transforms.ToTensor()\n",
        "dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=50000, shuffle=False)\n",
        "\n",
        "images, _ = next(iter(loader))  # all 50k images\n",
        "\n",
        "# Compute per-channel mean and std\n",
        "mean = images.mean(dim=[0,2,3])\n",
        "std = images.std(dim=[0,2,3])\n",
        "\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Std:\", std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yv3LMb4vpiS",
        "outputId": "49f355a2-c485-4984-d934-187d65dd3f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 44.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: tensor([0.4914, 0.4822, 0.4465])\n",
            "Std: tensor([0.2470, 0.2435, 0.2616])\n"
          ]
        }
      ]
    }
  ]
}